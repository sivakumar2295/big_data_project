{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library import\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os, random, json\n",
    "spark=SparkSession.builder.master(\"local\").appName(\"studentmarkpractice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script execution for raw data to pre-landing\n",
    "class Raw_to_prelanding:\n",
    "    \n",
    "    \"\"\"Script to read raw file from local path to pre landing..\"\"\"\n",
    "    \n",
    "    def __init__(self,file_parameter):\n",
    "        \n",
    "        \"\"\"function to get input parameters to read the file from local path\"\"\"\n",
    "        self.file_parameter=file_parameter\n",
    "\n",
    "    def read_csv(self):\n",
    "        return spark.read.format(self.file_parameter['src_format']).option(\"header\",\"True\").load(self.file_parameter['src_path'])\n",
    "    \n",
    "    def write_csv(self,df):\n",
    "        df.write.format(self.file_parameter['dest_format']).mode(\"overwrite\").save(self.file_parameter['dest_path'])\n",
    "        \n",
    "    def create_view(self,df):\n",
    "        df.createOrReplaceTempView(self.file_parameter['view_name'])\n",
    "        \n",
    "    def open_dir(self):\n",
    "        os.chdir(self.file_parameter['dest_path'])\n",
    "        dest_file_path=f\"{self.file_parameter['view_name']}.csv\"\n",
    "        for file in os.listdir():\n",
    "        # Check whether file is in text format or not\n",
    "            if file.endswith(\".csv\"):\n",
    "                src_file_path = f\"{file}\"\n",
    "                os.rename(src_file_path,dest_file_path)\n",
    "            else:\n",
    "                src_file_path = f\"{file}\"\n",
    "                os.remove(src_file_path)\n",
    "        \n",
    "    def dynamic_data_generate(self):\n",
    "        studentid=spark.sql(\"select Student_ID from studentdetails\")\n",
    "        studentcount=studentid.count()\n",
    "        subjectid=spark.sql(\"select Subject_ID from subjectdetails\")\n",
    "        subjectcount=subjectid.count()\n",
    "        month = [\"11-26-2021\",\"12-26-2021\",\"01-26-2022\"]\n",
    "        datastr=\"[\"\n",
    "\n",
    "        for x in range(studentcount):\n",
    "\n",
    "            for y in month:\n",
    "\n",
    "                for z in range(subjectcount-1):\n",
    "                    datastr=datastr+'{\"Student_ID\":'+studentid.collect()[x][0]+',\"Date\":\"'+y+'\",\"Subject_ID\":'+subjectid.collect()[z][0]+',\"Marks\":'+str(random.randint(40,100))+'},'\n",
    "        datastr=datastr+'{\"Student_ID\":'+studentid.collect()[x][0]+',\"Date\":\"'+y+'\",\"Subject_ID\":'+subjectid.collect()[z][0]+',\"Marks\":'+str(random.randint(40,100))+'}'        \n",
    "        datastr=datastr+\"]\"\n",
    "        \n",
    "        data=json.loads(datastr)\n",
    "        df = spark.createDataFrame(data)\n",
    "        self.write_csv(df)\n",
    "        self.open_dir()\n",
    "    \n",
    "    def main_block(self):\n",
    "        \n",
    "        \"\"\"main execution block\"\"\"\n",
    "        df=self.read_csv() \n",
    "        self.write_csv(df)\n",
    "        self.create_view(df)\n",
    "        self.open_dir()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    file_parameter1={\n",
    "        \"dest_format\":\"csv\",\n",
    "        \"src_path\":\"C:/Git_Repo/big_data_project/raw_data/raw_files/school/studentdetails.csv\",\n",
    "        \"src_format\":\"csv\",\n",
    "        \"dest_path\":\"C:/Git_Repo/big_data_project/data_files/pre_landing/raw_files/school/student\",\n",
    "        \"view_name\":\"studentdetails\"\n",
    "    }\n",
    "    \n",
    "    file_parameter2={\n",
    "        \"dest_format\":\"csv\",\n",
    "        \"src_path\":\"C:/Git_Repo/big_data_project/raw_data/raw_files/school/subjectdetails.csv\",\n",
    "        \"src_format\":\"csv\",\n",
    "        \"dest_path\":\"C:/Git_Repo/big_data_project/data_files/pre_landing/raw_files/school/subject\",\n",
    "        \"view_name\":\"subjectdetails\"\n",
    "    }\n",
    "    \n",
    "    file_parameter3={\n",
    "        \"dest_format\":\"csv\",\n",
    "        \"dest_path\":\"C:/Git_Repo/big_data_project/data_files/pre_landing/raw_files/school/marks\",\n",
    "        \"view_name\":\"markdetails\"\n",
    "    }\n",
    "    \n",
    "    prelanding_obj1=Raw_to_prelanding(file_parameter1)\n",
    "    prelanding_obj2=Raw_to_prelanding(file_parameter2)\n",
    "    prelanding_obj3=Raw_to_prelanding(file_parameter3)\n",
    "    prelanding_obj1.main_block()\n",
    "    prelanding_obj2.main_block()\n",
    "    prelanding_obj3.dynamic_data_generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
